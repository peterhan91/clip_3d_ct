{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e534c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad6b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_ct(file_path, metadata_row, hu_range=(-1000, 1000)):\n",
    "    \"\"\"\n",
    "    Load and preprocess a CT scan:\n",
    "    - Reorient to RAS (Right-Anterior-Superior) orientation\n",
    "    - Apply DICOM rescale\n",
    "    - Clip to [-1000, 1000] HU range\n",
    "    \"\"\"\n",
    "    img = nib.load(str(file_path))\n",
    "    \n",
    "    # Reorient to RAS orientation (Right-Anterior-Superior)\n",
    "    # This ensures consistent orientation: left->right, posterior->anterior, inferior->superior\n",
    "    img = nib.as_closest_canonical(img)\n",
    "    \n",
    "    data = img.get_fdata()\n",
    "    if metadata_row is not None:\n",
    "        # Apply DICOM rescale if metadata is provided\n",
    "        slope = float(metadata_row['RescaleSlope'])\n",
    "        intercept = float(metadata_row['RescaleIntercept'])\n",
    "        data = data * slope + intercept\n",
    "    else:\n",
    "        # Default rescale if no metadata is provided\n",
    "        slope = 1.0\n",
    "        intercept = 0.0\n",
    "        data = data * slope + intercept\n",
    "    data = np.clip(data, hu_range[0], hu_range[1])\n",
    "    return data.astype(np.float32)\n",
    "\n",
    "\n",
    "def resize_and_pad_3d_to_target(volume, target_shape=(160, 224, 224)):\n",
    "    \"\"\"\n",
    "    Aspect-ratio-preserving resize to fit within target_shape, then center-pad to match it.\n",
    "    Normalize HU values to [-1, 1] range, then convert to uint8 [0, 255].\n",
    "    \"\"\"\n",
    "    d, h, w = volume.shape\n",
    "    target_d, target_h, target_w = target_shape\n",
    "    scale = min(target_d / d, target_h / h, target_w / w)\n",
    "    new_d, new_h, new_w = [int(round(x * scale)) for x in (d, h, w)]\n",
    "\n",
    "    # Resize (trilinear) - keeping HU values\n",
    "    tensor = torch.tensor(volume).unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)\n",
    "    tensor_resized = F.interpolate(\n",
    "        tensor, size=(new_d, new_h, new_w), mode='trilinear', align_corners=False\n",
    "    )\n",
    "    resized = tensor_resized.squeeze().cpu().numpy()\n",
    "\n",
    "    # Center padding with 0 HU (water density)\n",
    "    pad_d = target_d - new_d\n",
    "    pad_h = target_h - new_h\n",
    "    pad_w = target_w - new_w\n",
    "    pad = (\n",
    "        pad_w // 2, pad_w - pad_w // 2,\n",
    "        pad_h // 2, pad_h - pad_h // 2,\n",
    "        pad_d // 2, pad_d - pad_d // 2,\n",
    "    )\n",
    "    padded = np.pad(\n",
    "        resized,\n",
    "        ((pad[4], pad[5]), (pad[2], pad[3]), (pad[0], pad[1])),\n",
    "        mode='constant',\n",
    "        constant_values=-1000  \n",
    "    )\n",
    "    \n",
    "    # Normalize to [-1, 1] then convert to [0, 255] for uint8\n",
    "    normalized = padded / 1000.0  # [-1, 1]\n",
    "    uint8_data = ((normalized + 1.0) / 2.0 * 255.0)  # Map [-1,1] to [0,255]\n",
    "    uint8_data = np.clip(uint8_data, 0, 255)\n",
    "    return uint8_data.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8762c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/tianyuhan/Documents/data/ct-rate/dataset/train/train_1/train_1_a/train_1_a_1.nii.gz\"\n",
    "metadata = pd.read_csv(\"../data/train_metadata.csv\")\n",
    "volumename = os.path.basename(path)\n",
    "\n",
    "metadata_row = metadata[metadata['VolumeName'] == volumename]\n",
    "ct = read_and_preprocess_ct(path, {'RescaleSlope': 1,\n",
    "                                   'RescaleIntercept': 0})\n",
    "ct = ct.transpose(2, 1, 0)  # Transpose to (depth, height, width)\n",
    "ct = resize_and_pad_3d_to_target(ct, target_shape=(160, 224, 224))\n",
    "print(ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27cf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ct_to_mp4(ct, out_path='ct_movie.mp4', fps=15, window=None):\n",
    "    \"\"\"\n",
    "    Save a 3D CT volume as an MP4 movie.\n",
    "    \n",
    "    Args:\n",
    "        ct: numpy array of shape (D, W, H)\n",
    "        out_path: output video file\n",
    "        fps: frames per second\n",
    "        window: (min, max) for intensity windowing (e.g., (0, 1024)). If None, auto window.\n",
    "    \"\"\"\n",
    "    D, W, H = ct.shape\n",
    "    \n",
    "    # Window the image (normalize for display)\n",
    "    if window is None:\n",
    "        vmin, vmax = np.percentile(ct, 1), np.percentile(ct, 99)\n",
    "    else:\n",
    "        vmin, vmax = window\n",
    "\n",
    "    # Setup video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(out_path, fourcc, fps, (H, W), isColor=False)\n",
    "\n",
    "    for i in range(D):\n",
    "        img = ct[i]  # Axial slice: shape (W, H)\n",
    "        # Normalize to 0-255 for uint8 display\n",
    "        # img = np.clip((img - vmin) / (vmax - vmin) * 255, 0, 255).astype(np.uint8)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)  # MP4 requires 3 channels\n",
    "        video.write(img)\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Saved video: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfd078c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video: /Users/tianyuhan/Documents/data/inspect/ct_movie.mp4\n"
     ]
    }
   ],
   "source": [
    "save_ct_to_mp4(ct[:, ::-1, :], out_path='/Users/tianyuhan/Documents/data/inspect/ct_movie.mp4', fps=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
